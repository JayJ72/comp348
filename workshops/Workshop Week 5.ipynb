{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration: Sentiment analysis\n",
    "\n",
    "In this part of the workshop we will walk through a system that uses the Naive Bayes classifiers of NLTK and scikit-learn to predict the review scores of NLTK's corpus of movie reviews. This corpus is used in [NLTK's chapter 6](http://www.nltk.org/book/ch06.html#document-classification). The corpus contains a selection of movie reviews, and a label as to whether the review is positive or negative. Classification of reviews as \"positive\" or \"negative\" is a task that is related to [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the movie review corpus\n",
    "\n",
    "The following code reads the movie reviews corpus and shows some statistics on the labels given to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative reviews: 1000\n",
      "Number of positive reviews: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of negative reviews:\", len(movie_reviews.fileids('neg')))\n",
    "print(\"Number of positive reviews:\", len(movie_reviews.fileids('pos')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code partitions the movie review corpus into a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "random.seed(1234)\n",
    "random.shuffle(documents)\n",
    "threshold1 = int(len(documents)*.6)\n",
    "threshold2 = int(len(documents)*.8)\n",
    "train = documents[:threshold1]\n",
    "devtest = documents[threshold1:threshold2]\n",
    "test = documents[threshold2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document features\n",
    "\n",
    "The following code defines a feature set of the 2000 most frequent non-stop words of the training set. The value of each feature is 1 if the word is present in the document, and 0 otherwise. This is what is generally called [one-hot encoding](https://en.wikipedia.org/wiki/One-hot). To build the list we will ignore word casing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "c = collections.Counter([w.lower() for (words,category) in train \n",
    "                                   for w in words if w.lower() not in stop])\n",
    "top2000words = [w for (w,count) in c.most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def document_features(words):\n",
    "    \"Return the document features for an NLTK classifier\"\n",
    "    words_lower = [w.lower() for w in words]\n",
    "    result = dict()\n",
    "    for w in top2000words:\n",
    "        result['has(%s)' % w] = (w in words_lower)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Naive Bayes\n",
    "\n",
    "The following code trains an NLTK Naive Bayes classifier using the training set, and reports the evaluation results on the training set and the dev-test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = [(document_features(x),y) for (x,y) in train]\n",
    "devtest_features = [(document_features(x),y) for (x,y) in devtest]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier,devtest_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier,train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the difference in accuracy between the test set and the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix features for sklearn\n",
    "\n",
    "The following code defines a second feature extractor that uses one-hot encoding on the same list of 2000 words, and which is suitable for sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vector_features(words):\n",
    "    \"Return a vector of features for sklearn\"\n",
    "    words_lower = [w.lower() for w in words]\n",
    "    result = []\n",
    "    for w in top2000words:\n",
    "        if w in words_lower:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn Naive Bayes\n",
    "\n",
    "This code generates the features for sklearn and trains and evaluates a multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vectors = [vector_features(x) for (x,y) in train]\n",
    "devtest_vectors = [vector_features(x) for (x,y) in devtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "sklearn_classifier = MultinomialNB()\n",
    "sklearn_classifier.fit(train_vectors, [y for (x,y) in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53500000000000003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sklearn_classifier.predict(devtest_vectors)\n",
    "true = [y for (x,y) in test]\n",
    "accuracy_score(true,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92249999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sklearn_classifier.predict(train_vectors)\n",
    "true = [y for (x,y) in train]\n",
    "accuracy_score(true,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the difference between train and devtest is much greater with sklearn. This might be because of differences in the default settings of the implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "sklean clearly overfits. What do you think you could do to reduce overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf with Naive Bayes\n",
    "\n",
    "The following code computes tf.idf of the training set and uses sklearn's multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sklearn's `TfidfVectorizer` takes a list of strings as the input, but in our previous experiments we had used the tokenised information, that is, the list of tokens provided by sklearn. We can use `TfidfTransformer` to process a list of tokens (see the [sklearn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)), \n",
    "but since we haven't covered it in the lectures, let's use the raw strings as our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [(movie_reviews.raw(fileid), category)\n",
    "         for category in movie_reviews.categories()\n",
    "         for fileid in movie_reviews.fileids(category)]\n",
    "random.seed(1234)\n",
    "random.shuffle(texts)\n",
    "threshold1 = int(len(texts)*.6)\n",
    "threshold2 = int(len(texts)*.8)\n",
    "text_train = texts[:threshold1]\n",
    "text_devtest = texts[threshold1:threshold2]\n",
    "text_test = texts[threshold2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(input='contents',stop_words='english',max_features=2000)\n",
    "text_tfidf_train = tfidf.fit_transform([x for (x,y) in text_train])\n",
    "text_tfidf_devtest = tfidf.transform([x for (x,y) in text_devtest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we used `tfidf.fit_transform` when using the training set, and `tfidf.transform` when using the test set. This is because we use the train set to learn the tfidf parameters \n",
    "(the 2000 most frequent words and their IDF), and then we apply that information when we want to compute the tfidf of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_tfidfclassifier = MultinomialNB()\n",
    "sklearn_tfidfclassifier.fit(text_tfidf_train,[y for (x,y) in text_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80500000000000005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score([y for (x,y) in text_devtest], sklearn_tfidfclassifier.predict(text_tfidf_devtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91416666666666668"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score([y for (x,y) in text_train], sklearn_tfidfclassifier.predict(text_tfidf_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "We observe much better results in the devtest set, and less difference between train and devtest sets. What does this mean in terms of overfitting, bias and variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "\n",
    "## Naive Bayes on Question Segmentation\n",
    "\n",
    "NLTK has a corpus of questions with their label under a particular classification scheme (e.g. `DESC` refers to a question expecting a descriptive answer, such as one starting with \"How\"; `HUM` refers to a question expecting an answer referring to a human). Here's some example of use of the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import qc\n",
    "train = qc.tuples(\"train.txt\")\n",
    "test = qc.tuples(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DESC:manner', 'How did serfdom develop in and then leave Russia ?'),\n",
       " ('ENTY:cremat', 'What films featured the character Popeye Doyle ?'),\n",
       " ('DESC:manner', \"How can I find a list of celebrities ' real names ?\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NUM:dist', 'How far is it from Denver to Aspen ?'),\n",
       " ('LOC:city', 'What county is Modesto , California in ?'),\n",
       " ('HUM:desc', 'Who was Galileo ?')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: All question types\n",
    "\n",
    "Write Python code that lists all the possible question types of the training set (remember: _never look at the test set_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: All general types\n",
    "\n",
    "The question types have two parts. The first part describes a general type, and the second part defines a subtype. For example, the question type `DESC:manner` belongs to the general `DESC` type and within that type to the `manner` subtype. Let's focus on the general types only. Write Python code that lists all the possible general types (there are 6 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Feature extractor\n",
    "\n",
    "Write a feature extractor function that uses individual words as features (\"one-hot encoding\"). To obtain the list of words, use the 100 most frequent words in the training set (since you aren’t supposed to use the test set to extract features). Note that we do not use a list of stop words now since the questions are very short, and some words such as 'how' are useful for question classification but are listed as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: NLTK Naive Bayes classifier\n",
    "\n",
    "Train an NLTK Naïve Bayes classifier with the features of the training set, and test it on the testing set. What accuracy do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: sklearn Naive Bayes classifier\n",
    "\n",
    "Convert the feature set to a document matrix suitable for sklearn, and train again using sklearn's Multinomial Naive Bayes classifier. Are the results different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Majority baseline\n",
    "\n",
    "What is the accuracy if we use a majority baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Naive Bayes by Hand\n",
    "\n",
    "The lecture notes give a walk-through for the computation of Naive Bayes of a document given the following small corpus of training documents. The table shows the frequency of specific keywords in each document of the corpus, together with the document class.\n",
    "\n",
    "| Doc. | Class | \"computer\" | \"machine\" | \"spreadsheet\" | \"money\" | \"budget\" |\n",
    "| -----| ----- | ---------- | --------- | ------------- | ------- | -------- |\n",
    "| d1   | c1    | 10         | 3         | 2             | 0       | 1        |\n",
    "| d2   | c1 |\t4 |\t6 |\t8 |\t2 |\t0|\n",
    "| d3 |\tc2 |\t2 |\t1 |\t0 |\t5 |\t4|\n",
    "| d4 |\tc2 |\t1 |\t2 |\t1 |\t8 |\t9|\n",
    "\n",
    "The lecture notes show how to classify the document with word frequencies (1,2,3,4,5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Apply Naive Bayes to classify the document with word vector (2,4,1,0,3) using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Apply Naive Bayes to classify the document with word vector (2,4,1,0,3) using \"add-1\" smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
